{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446b70a2",
   "metadata": {},
   "source": [
    "# Sci-kit Learn Models for Building Energy Modelling\n",
    "\n",
    "Each regressor has its own strengths and weaknesses, making the choice dependent on the specific dataset characteristics, desired interpretability, and performance requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97af6a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression model library from Scikit-Learn library\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "    \n",
    "# Make array of models. Each model is an array of two elements.\n",
    "# First element is a model-name, second is a model itself\n",
    "models = [#['RandomForestRegressor', RandomForestRegressor(n_estimators = 1000, random_state = 42)],\n",
    "#['AdaBoostRegressor', AdaBoostRegressor(n_estimators = 1000, random_state = 42)],\n",
    "#['BaggingRegressor', BaggingRegressor(n_estimators = 1000, random_state = 42)],\n",
    "#['DecisionTreeRegressor', DecisionTreeRegressor(random_state = 42)],\n",
    "#['DummyRegressor', DummyRegressor()],\n",
    "#['ExtraTreeRegressor', ExtraTreeRegressor(random_state = 42)],\n",
    "#['ExtraTreesRegressor', ExtraTreesRegressor(n_estimators = 1000, random_state = 42)],\n",
    "['GaussianProcessRegressor', GaussianProcessRegressor(random_state = 42)],\n",
    "# ['GradientBoostingRegressor', GradientBoostingRegressor(n_estimators = 1000, random_state = 42)],\n",
    "# ['HuberRegressor', HuberRegressor()],\n",
    "# ['KNeighborsRegressor', KNeighborsRegressor()],\n",
    "# ['MLPRegressor', MLPRegressor(random_state = 42)],\n",
    "# ['PassiveAggressiveRegressor', PassiveAggressiveRegressor(random_state = 42)],\n",
    "# ['RANSACRegressor', RANSACRegressor(random_state = 42)],\n",
    "# ['SGDRegressor', SGDRegressor(random_state = 42)],\n",
    "# ['TheilSenRegressor', TheilSenRegressor(random_state = 42)]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f45f4",
   "metadata": {},
   "source": [
    "## 1. Load cleaned meter data, weather data and schedule data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89b8cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meter Data:\n",
      "                     power_kw         site_name\n",
      "datetime                                       \n",
      "2019-05-01 00:00:00    40.856  J Don Boney Bldg\n",
      "2019-05-01 00:15:00    42.392  J Don Boney Bldg\n",
      "2019-05-01 00:30:00    42.776  J Don Boney Bldg\n",
      "2019-05-01 00:45:00    41.472  J Don Boney Bldg\n",
      "2019-05-01 01:00:00    39.552  J Don Boney Bldg\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 35136 entries, 2019-05-01 00:00:00 to 2020-04-30 23:45:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   power_kw   35132 non-null  float64\n",
      " 1   site_name  35136 non-null  object \n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 823.5+ KB\n",
      "None\n",
      "Resampled Meter Data:\n",
      "datetime\n",
      "2019-05-01 00:00:00    41.874\n",
      "2019-05-01 01:00:00    36.749\n",
      "2019-05-01 02:00:00    33.984\n",
      "2019-05-01 03:00:00    31.834\n",
      "2019-05-01 04:00:00    31.642\n",
      "Freq: h, Name: power_kw, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/6vcnqd4d3nlcwtdmsgb31hx40000gn/T/ipykernel_96160/289217687.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  meter_data_hourly = meter_data['power_kw'].resample('H').mean()\n"
     ]
    }
   ],
   "source": [
    "# Define output file name and path\n",
    "input_dir = 'data/chapter4/campus-bldg/cleaned'  # Directory where output files will be saved\n",
    "input_file = os.path.join(input_dir, 'clean_meter_data.csv')     # Output CSV file name\n",
    "\n",
    "# Load cleaned meter data\n",
    "meter_data = pd.read_csv(input_file, index_col=0, parse_dates=True)\n",
    "\n",
    "# Display the first few rows of the meter data\n",
    "print(\"Meter Data:\")\n",
    "print(meter_data.head())\n",
    "print(meter_data.info())\n",
    "\n",
    "# Resample the meter data to hourly frequency\n",
    "meter_data_hourly = meter_data['power_kw'].resample('H').mean()\n",
    "\n",
    "# Display the first few rows of the resampled meter data\n",
    "print(\"Resampled Meter Data:\")\n",
    "print(meter_data_hourly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee1de885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weather Data:\n",
      "                                          time        summary  \\\n",
      "datetime                                                        \n",
      "2019-01-01 00:00:00  2019-01-01 00:00:00-06:00  Mostly Cloudy   \n",
      "2019-01-01 01:00:00  2019-01-01 01:00:00-06:00  Mostly Cloudy   \n",
      "2019-01-01 02:00:00  2019-01-01 02:00:00-06:00  Partly Cloudy   \n",
      "2019-01-01 03:00:00  2019-01-01 03:00:00-06:00  Partly Cloudy   \n",
      "2019-01-01 04:00:00  2019-01-01 04:00:00-06:00  Partly Cloudy   \n",
      "\n",
      "                                    icon  precipIntensity  precipAccumulation  \\\n",
      "datetime                                                                        \n",
      "2019-01-01 00:00:00  partly-cloudy-night              0.0                 0.0   \n",
      "2019-01-01 01:00:00  partly-cloudy-night              0.0                 0.0   \n",
      "2019-01-01 02:00:00  partly-cloudy-night              0.0                 0.0   \n",
      "2019-01-01 03:00:00  partly-cloudy-night              0.0                 0.0   \n",
      "2019-01-01 04:00:00  partly-cloudy-night              0.0                 0.0   \n",
      "\n",
      "                    precipType  temperature  apparentTemperature  dewPoint  \\\n",
      "datetime                                                                     \n",
      "2019-01-01 00:00:00       none         7.00                 5.94      5.91   \n",
      "2019-01-01 01:00:00       none         6.71                 6.29      5.59   \n",
      "2019-01-01 02:00:00       none         6.93                 8.54      5.79   \n",
      "2019-01-01 03:00:00       none         6.52                 6.28      5.45   \n",
      "2019-01-01 04:00:00       none         5.36                 4.14      4.81   \n",
      "\n",
      "                     pressure  windSpeed  windGust  windBearing  cloudCover  \\\n",
      "datetime                                                                      \n",
      "2019-01-01 00:00:00   1017.46       1.74      1.60       229.14        0.86   \n",
      "2019-01-01 01:00:00   1017.48       1.19      0.72       209.90        0.77   \n",
      "2019-01-01 02:00:00   1017.86       0.33      1.38       343.99        0.53   \n",
      "2019-01-01 03:00:00   1017.95       1.07      2.48        15.28        0.39   \n",
      "2019-01-01 04:00:00   1017.94       1.67      3.41        28.33        0.55   \n",
      "\n",
      "                     snowAccumulation  \n",
      "datetime                               \n",
      "2019-01-01 00:00:00               0.0  \n",
      "2019-01-01 01:00:00               0.0  \n",
      "2019-01-01 02:00:00               0.0  \n",
      "2019-01-01 03:00:00               0.0  \n",
      "2019-01-01 04:00:00               0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 17544 entries, 2019-01-01 00:00:00 to 2020-12-31 23:00:00\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   time                 17544 non-null  object \n",
      " 1   summary              17544 non-null  object \n",
      " 2   icon                 17544 non-null  object \n",
      " 3   precipIntensity      17544 non-null  float64\n",
      " 4   precipAccumulation   17544 non-null  float64\n",
      " 5   precipType           17544 non-null  object \n",
      " 6   temperature          17544 non-null  float64\n",
      " 7   apparentTemperature  17544 non-null  float64\n",
      " 8   dewPoint             17544 non-null  float64\n",
      " 9   pressure             17544 non-null  float64\n",
      " 10  windSpeed            17544 non-null  float64\n",
      " 11  windGust             17544 non-null  float64\n",
      " 12  windBearing          17544 non-null  float64\n",
      " 13  cloudCover           17544 non-null  float64\n",
      " 14  snowAccumulation     17544 non-null  float64\n",
      "dtypes: float64(11), object(4)\n",
      "memory usage: 2.1+ MB\n",
      "None\n",
      "\n",
      "Outdoor Temperature and Dewpoint:\n",
      "                     outdoor_temp  outdoor_dewpoint  outdoor_cloudcover\n",
      "datetime                                                               \n",
      "2019-05-01 00:00:00         25.19             22.06                0.99\n",
      "2019-05-01 01:00:00         24.78             21.85                0.73\n",
      "2019-05-01 02:00:00         24.68             21.74                0.96\n",
      "2019-05-01 03:00:00         24.32             21.60                0.70\n",
      "2019-05-01 04:00:00         24.04             21.97                0.44\n"
     ]
    }
   ],
   "source": [
    "# Load weather data\n",
    "weather_file = os.path.join(input_dir, '77051_2019-01-01_2020-12-31_Weather.csv')\n",
    "weather_data = pd.read_csv(weather_file, index_col=['datetime'], parse_dates=True)\n",
    "\n",
    "# Display the first few rows of the weather data\n",
    "print(\"\\nWeather Data:\")\n",
    "print(weather_data.head())\n",
    "print(weather_data.info())\n",
    "\n",
    "# Subset the weather data to the same time period as the meter data\n",
    "weather_data = weather_data[meter_data_hourly.index.min():meter_data_hourly.index.max()]\n",
    "\n",
    "# Select outdoor temperature and dewpoint\n",
    "outdoor_temp = weather_data['temperature']\n",
    "outdoor_dewpoint = weather_data['dewPoint']\n",
    "outdoor_cloudcover = weather_data['cloudCover']\n",
    "\n",
    "# Display the first few rows of the outdoor temperature and dewpoint data\n",
    "print(\"\\nOutdoor Temperature and Dewpoint:\")\n",
    "print(pd.DataFrame({'outdoor_temp': outdoor_temp, 'outdoor_dewpoint': outdoor_dewpoint, 'outdoor_cloudcover': outdoor_cloudcover}).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdf531cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schedule Data:\n",
      "\n",
      "Resampled Schedule Data:\n",
      "                    seasonal\n",
      "2019-05-01 00:00:00  Regular\n",
      "2019-05-01 01:00:00  Regular\n",
      "2019-05-01 02:00:00  Regular\n",
      "2019-05-01 03:00:00  Regular\n",
      "2019-05-01 04:00:00  Regular\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8784 entries, 2019-05-01 00:00:00 to 2020-04-30 23:00:00\n",
      "Freq: h\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   seasonal  8784 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 137.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load seasonal schedule data\n",
    "schedule_file = os.path.join(input_dir, 'schedule.csv')\n",
    "schedule_data = pd.read_csv(schedule_file, index_col=['Date'], parse_dates=True)\n",
    "\n",
    "# Display the first few rows of the schedule data\n",
    "print(\"\\nSchedule Data:\")\n",
    "# print(schedule_data.head())\n",
    "# print(schedule_data.info())\n",
    "\n",
    "# Rename the columns for clarity\n",
    "schedule_data.columns = ['seasonal']\n",
    "\n",
    "# Resample the schedule data to hourly frequency\n",
    "schedule_data = schedule_data.reindex(pd.date_range(start=meter_data_hourly.index.min(), \n",
    "                                                   end=meter_data_hourly.index.max(), \n",
    "                                                   freq='h')).ffill().bfill()\n",
    "\n",
    "# Display the first few rows of the resampled schedule data\n",
    "print(\"\\nResampled Schedule Data:\")\n",
    "print(schedule_data.head())\n",
    "print(schedule_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9fe0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)\n",
      "[5 6 7] [ 8  9 10]\n",
      "[ 5  6  7  8  9 10] [11 12  1]\n",
      "[ 5  6  7  8  9 10 11 12  1] [2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Create an array of months from the meter data\n",
    "months = np.array([meter_data_hourly.index.month.unique()])[0]\n",
    "n_splits = 3\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Display the months and number of splits\n",
    "print(tscv)\n",
    "\n",
    "for train_index, test_index in tscv.split(months):\n",
    "    month_train, month_test = months[train_index], months[test_index]\n",
    "    print(month_train, month_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79d7a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test indices for time-series split and every-fourth-month split\n",
    "def create_train_test_indices(months):\n",
    "    train_test_lists = []\n",
    "    \n",
    "    #Get time-series split version\n",
    "    n_splits = 3\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    for train_index, test_index in tscv.split(months):\n",
    "        month_train, month_test = months[train_index], months[test_index]\n",
    "        train_test_lists.append([month_train, month_test])\n",
    "        \n",
    "    #Add the 'every-fourth-month' version\n",
    "    train_test_lists.append([np.concatenate([months[0:3], months[4:7], \n",
    "                                            months[8:11]]), np.array([months[4], months[7], months[11]])])\n",
    "    \n",
    "    return train_test_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02b6b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Indices:\n",
      "Each element is a list of two arrays: train and test indices\n",
      "[5 6 7] [ 8  9 10]\n",
      "[ 5  6  7  8  9 10] [11 12  1]\n",
      "[ 5  6  7  8  9 10 11 12  1] [2 3 4]\n",
      "[ 5  6  7  9 10 11  1  2  3] [ 9 12  4]\n"
     ]
    }
   ],
   "source": [
    "# Create train-test indices\n",
    "train_test_lists = create_train_test_indices(months)\n",
    "\n",
    "# Display the train-test indices\n",
    "print(\"Train-Test Indices:\")\n",
    "print(\"Each element is a list of two arrays: train and test indices\")\n",
    "for train_index, test_index in train_test_lists:  \n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49685d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  6,  7,  9, 10, 11,  1,  2,  3], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45e7c006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data:\n",
      "datetime\n",
      "2019-05-01 00:00:00    41.874\n",
      "2019-05-01 01:00:00    36.749\n",
      "2019-05-01 02:00:00    33.984\n",
      "2019-05-01 03:00:00    31.834\n",
      "2019-05-01 04:00:00    31.642\n",
      "Name: power_kw, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create a list of training months\n",
    "training_data = meter_data_hourly[meter_data_hourly.index.month.isin(train_index)]\n",
    "# Display the first few rows of the training data\n",
    "print(\"\\nTraining Data:\")\n",
    "print(training_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7845f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Training Data:\n",
      "                     energy  temperature  dewPoint  cloudCover  \\\n",
      "2019-05-01 00:00:00  41.874        25.19     22.06        0.99   \n",
      "2019-05-01 01:00:00  36.749        24.78     21.85        0.73   \n",
      "2019-05-01 02:00:00  33.984        24.68     21.74        0.96   \n",
      "2019-05-01 03:00:00  31.834        24.32     21.60        0.70   \n",
      "2019-05-01 04:00:00  31.642        24.04     21.97        0.44   \n",
      "\n",
      "                     seasonal_Break  seasonal_Holiday  seasonal_Regular  \\\n",
      "2019-05-01 00:00:00           False             False              True   \n",
      "2019-05-01 01:00:00           False             False              True   \n",
      "2019-05-01 02:00:00           False             False              True   \n",
      "2019-05-01 03:00:00           False             False              True   \n",
      "2019-05-01 04:00:00           False             False              True   \n",
      "\n",
      "                     seasonal_Summer  \n",
      "2019-05-01 00:00:00            False  \n",
      "2019-05-01 01:00:00            False  \n",
      "2019-05-01 02:00:00            False  \n",
      "2019-05-01 03:00:00            False  \n",
      "2019-05-01 04:00:00            False  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6588 entries, 2019-05-01 00:00:00 to 2020-03-31 23:00:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   energy            6588 non-null   float64\n",
      " 1   temperature       6588 non-null   float64\n",
      " 2   dewPoint          6588 non-null   float64\n",
      " 3   cloudCover        6588 non-null   float64\n",
      " 4   seasonal_Break    6588 non-null   bool   \n",
      " 5   seasonal_Holiday  6588 non-null   bool   \n",
      " 6   seasonal_Regular  6588 non-null   bool   \n",
      " 7   seasonal_Summer   6588 non-null   bool   \n",
      "dtypes: bool(4), float64(4)\n",
      "memory usage: 283.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge the training data with weather and schedule data\n",
    "training_data = pd.merge(pd.DataFrame({\"energy\":training_data}), outdoor_temp, right_index=True, left_index=True)\n",
    "training_data = pd.merge(training_data, outdoor_dewpoint, right_index=True, left_index=True)\n",
    "training_data = pd.merge(training_data, outdoor_cloudcover, right_index=True, left_index=True)\n",
    "\n",
    "# Merge the training data with schedule data dummy variable\n",
    "training_data = pd.merge(training_data, pd.get_dummies(schedule_data), right_index=True, left_index=True)\n",
    "\n",
    "# Display the first few rows of the merged training data\n",
    "print(\"\\nMerged Training Data:\")\n",
    "print(training_data.head())\n",
    "print(training_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78e83356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a list of training and testing data\n",
    "def get_features_and_labels(meter_data_hourly, outdoor_temp, outdoor_dewpoint, outdoor_cloudcover, schedule, months):\n",
    "    data = meter_data_hourly[meter_data_hourly.index.month.isin(months)]\n",
    "    data = pd.merge(pd.DataFrame({\"energy\":data}), outdoor_temp, right_index=True, left_index=True)\n",
    "    data = pd.merge(data, outdoor_dewpoint, right_index=True, left_index=True)\n",
    "    data = pd.merge(data, outdoor_cloudcover, right_index=True, left_index=True)\n",
    "    data = pd.merge(data, pd.get_dummies(schedule), right_index=True, left_index=True)\n",
    "    \n",
    "    features = pd.concat((pd.get_dummies(data.index.hour),\n",
    "                            pd.get_dummies(data.index.dayofweek),\n",
    "                            data.drop([\"energy\"], axis=1).reset_index(drop=True)),axis=1)\n",
    "    \n",
    "    features = features.ffill().bfill()\n",
    "    \n",
    "    # Convert features to numpy array\n",
    "    labels = data[\"energy\"].values\n",
    "    features = np.array(features)\n",
    "    \n",
    "    return features, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59f10dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test indices for the first split\n",
    "train_features, train_labels = get_features_and_labels(meter_data_hourly, outdoor_temp, outdoor_dewpoint, outdoor_cloudcover, schedule_data, train_index)\n",
    "test_features, test_labels = get_features_and_labels(meter_data_hourly, outdoor_temp, outdoor_dewpoint, outdoor_cloudcover, schedule_data, test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d59c4",
   "metadata": {},
   "source": [
    "## 3. Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef2f9ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: -0.0392760366399556\n",
      "\n",
      "Model Metrics:\n",
      "R^2 Score: -0.0393\n",
      "Mean Absolute Error: 7.9542\n",
      "Mean Squared Error: 104.7918\n",
      "Root Mean Squared Error: 10.2368\n",
      "CVRSME: 0.2452\n"
     ]
    }
   ],
   "source": [
    "# Train a dummy regressor as a baseline model\n",
    "testmodel = DummyRegressor()\n",
    "testmodel.fit(train_features, train_labels)\n",
    "\n",
    "# Predict using the trained model\n",
    "predictions = testmodel.predict(test_features)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "r2 = r2_score(test_labels, predictions)\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Calculate the metrics for the model\n",
    "metrics = {\n",
    "    'R^2 Score': r2,\n",
    "    'Mean Absolute Error': np.mean(np.abs(test_labels - predictions)),\n",
    "    'Mean Squared Error': np.mean((test_labels - predictions) ** 2),\n",
    "    'Root Mean Squared Error': np.sqrt(np.mean((test_labels - predictions) ** 2)),\n",
    "    'CVRSME': np.sqrt(np.mean((test_labels - predictions) ** 2)) / np.mean(test_labels)\n",
    "}\n",
    "# Display the metrics\n",
    "print(\"\\nModel Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Save the model metrics to a CSV file\n",
    "output_dir = 'data/chapter4/campus-bldg/models'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'model_metrics.csv')\n",
    "metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "# Add model name to the metrics DataFrame\n",
    "metrics_df.insert(0, 'Model', 'DummyRegressor')\n",
    "# Add site name to the metrics DataFrame\n",
    "metrics_df.insert(0, 'Site', 'Campus Building')\n",
    "\n",
    "# Save the metrics DataFrame to a CSV file\n",
    "metrics_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65f3c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for train-test split [5 6 7] - [ 8  9 10]: -0.0030925894992683833\n",
      "R^2 Score for train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.7170448993234819\n",
      "R^2 Score for train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: -2.2216996262480748e-05\n",
      "R^2 Score for train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: -0.0392760366399556\n"
     ]
    }
   ],
   "source": [
    "## Loop through training data\n",
    "index = 0\n",
    "# Loop through each train-test split\n",
    "for train_index, test_index in train_test_lists:\n",
    "    # Get features and labels for training and testing data\n",
    "    train_features, train_labels = get_features_and_labels(meter_data_hourly, outdoor_temp, outdoor_dewpoint, outdoor_cloudcover, schedule_data, train_index)\n",
    "    test_features, test_labels = get_features_and_labels(meter_data_hourly, outdoor_temp, outdoor_dewpoint, outdoor_cloudcover, schedule_data, test_index)\n",
    "    \n",
    "    # Train a dummy regressor as a baseline model\n",
    "    testmodel = DummyRegressor()\n",
    "    testmodel.fit(train_features, train_labels)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    predictions = testmodel.predict(test_features)\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    r2 = r2_score(test_labels, predictions)\n",
    "    print(f\"R^2 Score for train-test split {train_index} - {test_index}: {r2}\")\n",
    "\n",
    "    # Calculate the metrics for the model\n",
    "    metrics = {\n",
    "        'R^2 Score': r2,\n",
    "        'Mean Absolute Error': np.mean(np.abs(test_labels - predictions)),\n",
    "        'Mean Squared Error': np.mean((test_labels - predictions) ** 2),\n",
    "        'Root Mean Squared Error': np.sqrt(np.mean((test_labels - predictions) ** 2)),\n",
    "        'CVRSME': np.sqrt(np.mean((test_labels - predictions) ** 2)) / np.mean(test_labels)\n",
    "    }\n",
    "\n",
    "    # Save the model metrics to a CSV file\n",
    "    output_file = os.path.join(output_dir, f'model_metrics_split_validation_{index}.csv')\n",
    "    metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "    # Add model name to the metrics DataFrame\n",
    "    metrics_df.insert(0, 'Model', 'DummyRegressor')\n",
    "    # Add site name to the metrics DataFrame\n",
    "    metrics_df.insert(0, 'Site', 'Campus Building')\n",
    "    metrics_df.to_csv(output_file, index=False)\n",
    "\n",
    "    # Increment the index for the next split\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa14c950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make array of models. Each model is an array of two elements.\n",
    "# First element is a model-name, second is the model parameters\n",
    "models = [['RandomForestRegressor', RandomForestRegressor(n_estimators = 1000, random_state = 42)],\n",
    "['AdaBoostRegressor', AdaBoostRegressor(n_estimators = 1000, random_state = 42)],\n",
    "['BaggingRegressor', BaggingRegressor(n_estimators = 1000, random_state = 42)],\n",
    "['DecisionTreeRegressor', DecisionTreeRegressor(random_state = 42)],\n",
    "['DummyRegressor', DummyRegressor()],\n",
    "['ExtraTreeRegressor', ExtraTreeRegressor(random_state = 42)],\n",
    "['ExtraTreesRegressor', ExtraTreesRegressor(n_estimators = 1000, random_state = 42)],\n",
    "['GaussianProcessRegressor', GaussianProcessRegressor(random_state = 42)],\n",
    "['GradientBoostingRegressor', GradientBoostingRegressor(n_estimators = 1000, random_state = 42)],\n",
    "['HuberRegressor', HuberRegressor()],\n",
    "['KNeighborsRegressor', KNeighborsRegressor()],\n",
    "['MLPRegressor', MLPRegressor(random_state = 42)],\n",
    "['PassiveAggressiveRegressor', PassiveAggressiveRegressor(random_state = 42)],\n",
    "['RANSACRegressor', RANSACRegressor(random_state = 42)],\n",
    "['SGDRegressor', SGDRegressor(random_state = 42)],\n",
    "['TheilSenRegressor', TheilSenRegressor(random_state = 42)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eca4ad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train-Test Split 0:\n",
      "\n",
      "Training model: RandomForestRegressor\n",
      "R^2 Score for RandomForestRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.2064117851544479\n",
      "\n",
      "Training model: AdaBoostRegressor\n",
      "R^2 Score for AdaBoostRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.1722833675949026\n",
      "\n",
      "Training model: BaggingRegressor\n",
      "R^2 Score for BaggingRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.20683288849167225\n",
      "\n",
      "Training model: DecisionTreeRegressor\n",
      "R^2 Score for DecisionTreeRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.06380737690898985\n",
      "\n",
      "Training model: DummyRegressor\n",
      "R^2 Score for DummyRegressor on train-test split [5 6 7] - [ 8  9 10]: -0.0030925894992683833\n",
      "\n",
      "Training model: ExtraTreeRegressor\n",
      "R^2 Score for ExtraTreeRegressor on train-test split [5 6 7] - [ 8  9 10]: -0.117488537124389\n",
      "\n",
      "Training model: ExtraTreesRegressor\n",
      "R^2 Score for ExtraTreesRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.03742913840212991\n",
      "\n",
      "Training model: GaussianProcessRegressor\n",
      "R^2 Score for GaussianProcessRegressor on train-test split [5 6 7] - [ 8  9 10]: -3.6029932733812906\n",
      "\n",
      "Training model: GradientBoostingRegressor\n",
      "R^2 Score for GradientBoostingRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.07246744177900866\n",
      "\n",
      "Training model: HuberRegressor\n",
      "R^2 Score for HuberRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.07379578246898999\n",
      "\n",
      "Training model: KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for KNeighborsRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.11775927628922422\n",
      "\n",
      "Training model: MLPRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for MLPRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.03906483705421382\n",
      "\n",
      "Training model: PassiveAggressiveRegressor\n",
      "R^2 Score for PassiveAggressiveRegressor on train-test split [5 6 7] - [ 8  9 10]: -0.1966216868383821\n",
      "\n",
      "Training model: RANSACRegressor\n",
      "R^2 Score for RANSACRegressor on train-test split [5 6 7] - [ 8  9 10]: -0.04693238409925149\n",
      "\n",
      "Training model: SGDRegressor\n",
      "R^2 Score for SGDRegressor on train-test split [5 6 7] - [ 8  9 10]: -8340323440882.027\n",
      "\n",
      "Training model: TheilSenRegressor\n",
      "R^2 Score for TheilSenRegressor on train-test split [5 6 7] - [ 8  9 10]: 0.11898717383519997\n",
      "All model metrics saved to data/chapter4/campus-bldg/models/predict_metrics_all_model_validation_0.csv\n",
      "\n",
      "Train-Test Split 1:\n",
      "\n",
      "Training model: RandomForestRegressor\n",
      "R^2 Score for RandomForestRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.6750791146949848\n",
      "\n",
      "Training model: AdaBoostRegressor\n",
      "R^2 Score for AdaBoostRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.25203477208692404\n",
      "\n",
      "Training model: BaggingRegressor\n",
      "R^2 Score for BaggingRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.6714177848587961\n",
      "\n",
      "Training model: DecisionTreeRegressor\n",
      "R^2 Score for DecisionTreeRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -1.2582759601500464\n",
      "\n",
      "Training model: DummyRegressor\n",
      "R^2 Score for DummyRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.7170448993234819\n",
      "\n",
      "Training model: ExtraTreeRegressor\n",
      "R^2 Score for ExtraTreeRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.963885235592465\n",
      "\n",
      "Training model: ExtraTreesRegressor\n",
      "R^2 Score for ExtraTreesRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.5589226198470003\n",
      "\n",
      "Training model: GaussianProcessRegressor\n",
      "R^2 Score for GaussianProcessRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -10.480733788959343\n",
      "\n",
      "Training model: GradientBoostingRegressor\n",
      "R^2 Score for GradientBoostingRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.6605669819177569\n",
      "\n",
      "Training model: HuberRegressor\n",
      "R^2 Score for HuberRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -1.5609885136490171\n",
      "\n",
      "Training model: KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for KNeighborsRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.8819406995244847\n",
      "\n",
      "Training model: MLPRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for MLPRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -1.1459528148159812\n",
      "\n",
      "Training model: PassiveAggressiveRegressor\n",
      "R^2 Score for PassiveAggressiveRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -0.45630885762886697\n",
      "\n",
      "Training model: RANSACRegressor\n",
      "R^2 Score for RANSACRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -1.0325826601774435\n",
      "\n",
      "Training model: SGDRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py:1608: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for SGDRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -7247751.137543494\n",
      "\n",
      "Training model: TheilSenRegressor\n",
      "R^2 Score for TheilSenRegressor on train-test split [ 5  6  7  8  9 10] - [11 12  1]: -1.3331760956757264\n",
      "All model metrics saved to data/chapter4/campus-bldg/models/predict_metrics_all_model_validation_1.csv\n",
      "\n",
      "Train-Test Split 2:\n",
      "\n",
      "Training model: RandomForestRegressor\n",
      "R^2 Score for RandomForestRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.16258099379039515\n",
      "\n",
      "Training model: AdaBoostRegressor\n",
      "R^2 Score for AdaBoostRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.13027322864320523\n",
      "\n",
      "Training model: BaggingRegressor\n",
      "R^2 Score for BaggingRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.16180994173302077\n",
      "\n",
      "Training model: DecisionTreeRegressor\n",
      "R^2 Score for DecisionTreeRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: -0.6458984753718537\n",
      "\n",
      "Training model: DummyRegressor\n",
      "R^2 Score for DummyRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: -2.2216996262480748e-05\n",
      "\n",
      "Training model: ExtraTreeRegressor\n",
      "R^2 Score for ExtraTreeRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: -0.5187589220363316\n",
      "\n",
      "Training model: ExtraTreesRegressor\n",
      "R^2 Score for ExtraTreesRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.16739812410413968\n",
      "\n",
      "Training model: GaussianProcessRegressor\n",
      "R^2 Score for GaussianProcessRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: -1.0255601092265354\n",
      "\n",
      "Training model: GradientBoostingRegressor\n",
      "R^2 Score for GradientBoostingRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.2887643941170106\n",
      "\n",
      "Training model: HuberRegressor\n",
      "R^2 Score for HuberRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.2827646818786508\n",
      "\n",
      "Training model: KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for KNeighborsRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.021049804594017507\n",
      "\n",
      "Training model: MLPRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for MLPRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.3492834170699862\n",
      "\n",
      "Training model: PassiveAggressiveRegressor\n",
      "R^2 Score for PassiveAggressiveRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.2702021476289409\n",
      "\n",
      "Training model: RANSACRegressor\n",
      "R^2 Score for RANSACRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: -0.22941448920237173\n",
      "\n",
      "Training model: SGDRegressor\n",
      "R^2 Score for SGDRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: -13008.266753595699\n",
      "\n",
      "Training model: TheilSenRegressor\n",
      "R^2 Score for TheilSenRegressor on train-test split [ 5  6  7  8  9 10 11 12  1] - [2 3 4]: 0.26698084279764644\n",
      "All model metrics saved to data/chapter4/campus-bldg/models/predict_metrics_all_model_validation_2.csv\n",
      "\n",
      "Train-Test Split 3:\n",
      "\n",
      "Training model: RandomForestRegressor\n",
      "R^2 Score for RandomForestRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.3804353686442362\n",
      "\n",
      "Training model: AdaBoostRegressor\n",
      "R^2 Score for AdaBoostRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: -0.19006313234885197\n",
      "\n",
      "Training model: BaggingRegressor\n",
      "R^2 Score for BaggingRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.37870838984163535\n",
      "\n",
      "Training model: DecisionTreeRegressor\n",
      "R^2 Score for DecisionTreeRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: -0.13234408645605544\n",
      "\n",
      "Training model: DummyRegressor\n",
      "R^2 Score for DummyRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: -0.0392760366399556\n",
      "\n",
      "Training model: ExtraTreeRegressor\n",
      "R^2 Score for ExtraTreeRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: -0.15231198020814896\n",
      "\n",
      "Training model: ExtraTreesRegressor\n",
      "R^2 Score for ExtraTreesRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.37419115435648964\n",
      "\n",
      "Training model: GaussianProcessRegressor\n",
      "R^2 Score for GaussianProcessRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: -1.6342119390462804\n",
      "\n",
      "Training model: GradientBoostingRegressor\n",
      "R^2 Score for GradientBoostingRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.3217282856093169\n",
      "\n",
      "Training model: HuberRegressor\n",
      "R^2 Score for HuberRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.2504080352567303\n",
      "\n",
      "Training model: KNeighborsRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/linear_model/_huber.py:343: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for KNeighborsRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.20162844479815822\n",
      "\n",
      "Training model: MLPRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryin/myenv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score for MLPRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.24085793520781784\n",
      "\n",
      "Training model: PassiveAggressiveRegressor\n",
      "R^2 Score for PassiveAggressiveRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.0085278760477977\n",
      "\n",
      "Training model: RANSACRegressor\n",
      "R^2 Score for RANSACRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: -0.33034710168355597\n",
      "\n",
      "Training model: SGDRegressor\n",
      "R^2 Score for SGDRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: -19460.586543522564\n",
      "\n",
      "Training model: TheilSenRegressor\n",
      "R^2 Score for TheilSenRegressor on train-test split [ 5  6  7  9 10 11  1  2  3] - [ 9 12  4]: 0.23505993916841272\n",
      "All model metrics saved to data/chapter4/campus-bldg/models/predict_metrics_all_model_validation_3.csv\n"
     ]
    }
   ],
   "source": [
    "# Loop through each train-test split\n",
    "index = 0\n",
    "# Loop through each train-test split\n",
    "for train_index, test_index in train_test_lists:\n",
    "    # Print the current train-test split indices\n",
    "    print(f\"\\nTrain-Test Split {index}:\")\n",
    "\n",
    "    # Define an empty DataFrame to store all metrics for each model\n",
    "    metrics_df_all = pd.DataFrame()\n",
    "\n",
    "    # Get features and labels for training and testing data\n",
    "    train_features, train_labels = get_features_and_labels(meter_data_hourly, outdoor_temp, outdoor_dewpoint, outdoor_cloudcover, schedule_data, train_index)\n",
    "    test_features, test_labels = get_features_and_labels(meter_data_hourly, outdoor_temp, outdoor_dewpoint, outdoor_cloudcover, schedule_data, test_index)\n",
    "    \n",
    "    # Loop through each model in the models array\n",
    "    for model_name, model in models:\n",
    "        print(f\"\\nTraining model: {model_name}\")\n",
    "        # Train the model\n",
    "        model.fit(train_features, train_labels)\n",
    "        \n",
    "        # Predict using the trained model\n",
    "        predictions = model.predict(test_features)\n",
    "        \n",
    "        # Evaluate the model's performance\n",
    "        r2 = r2_score(test_labels, predictions)\n",
    "        print(f\"R^2 Score for {model_name} on train-test split {train_index} - {test_index}: {r2}\")\n",
    "\n",
    "        # Calculate the metrics for the model\n",
    "        metrics = {\n",
    "            'R^2 Score': r2,\n",
    "            'Mean Absolute Error': np.mean(np.abs(test_labels - predictions)),\n",
    "            'Mean Squared Error': np.mean((test_labels - predictions) ** 2),\n",
    "            'Root Mean Squared Error': np.sqrt(np.mean((test_labels - predictions) ** 2)),\n",
    "            'CVRSME': np.sqrt(np.mean((test_labels - predictions) ** 2)) / np.mean(test_labels)\n",
    "        }\n",
    "\n",
    "        # Save the model metrics to a CSV file\n",
    "        # output_file = os.path.join(output_dir, f'model_metrics_{model_name}_split_validation_{index}.csv')\n",
    "        metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "        # Add model name to the metrics DataFrame\n",
    "        metrics_df.insert(0, 'Model', model_name)\n",
    "        # Add site name to the metrics DataFrame\n",
    "        metrics_df.insert(0, 'Site', 'Campus Building')\n",
    "        # metrics_df.to_csv(output_file, index=False)\n",
    "\n",
    "        # Append the metrics DataFrame for the current model to the all metrics DataFrame\n",
    "        # This will accumulate metrics for all models across all splits\n",
    "        if metrics_df_all.empty:\n",
    "            metrics_df_all = metrics_df\n",
    "        else:\n",
    "            # Concatenate the current model's metrics DataFrame with the all metrics DataFrame\n",
    "            metrics_df_all = pd.concat([metrics_df_all, metrics_df])\n",
    "\n",
    "    # Save all model metrics to a single CSV file\n",
    "    all_metrics_output_file = os.path.join(output_dir, f'predict_metrics_all_model_validation_{index}.csv')\n",
    "    metrics_df_all.to_csv(all_metrics_output_file, index=False)\n",
    "    print(f\"All model metrics saved to {all_metrics_output_file}\")\n",
    "\n",
    "    # Increment the index for the next split\n",
    "    index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
